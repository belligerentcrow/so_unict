# 10 Lezione -- Sistemi Operativi

---

<!-- TOC -->
- [Recap](#recap)
- [Shortest Job First -- Scheduling per Brevita'](#shortest-job-first----scheduling-per-brevita)
- [Shortest Remaining Time Next](#shortest-remaining-time-next)
- [Scheduling Round-Robin](#scheduling-round-robin)
    - [Sistemi interattivi e priorita'](#sistemi-interattivi-e-priorita)
- [Aging](#aging)
- [Scheduling a code multiple](#scheduling-a-code-multiple)
<!-- /TOC -->

---

## Recap 

Tematica dello scheduling -- Algoritmi Scheduling dei sistemi batch.  

## Shortest Job First -- Scheduling per Brevita' 

Nello scegliere il job piu' piccolo dobbiamo sapere quanto e' grande. 
* Ipotesi: **sappiamo quanto tempo impieghera' il job.** Potrebbe dipendere dagli input. Pero' nello specifico nei sistemi batch diventa plausibile, perhce' hanno a che fare con dei job ricorrenti e categorizzabili per similitudine. Possiamo fare una stima --> Di quanto un task impieghi in termini di tempo.   

Data questa ipotesi possiamo applicare lo scheduling SJF. --> **Scegliamo quello piu' breve ogni volta**  

Valutando tempo di attesa vs tempo di completamento:  
Caso P1 = 24s, P2 = 3s, P3 = 3s.  
P1 ta: 6, P2 ta: 0, P3 ta: 3.  
P1 tc: 30, P2 tc: 3, P3 tc: 6.  
Cambia l'ordine --> Lo SJF non funziona meglio solo con questo ma in alcuni specifici casi e' ottimale.  (?)  

* Porta a tempi che comunque non possono essere migliorati. Si riordinano i processi schedulati mettendo davanti quelli piu' piccoli e in fondo quelli piu' grandi.  

* Cerca il minimo possibile sia del tempo medio di attesa che del tempo medio di completamento.  

--> Quello che fa l'algoritmo e' sostanzialmente uno switch di "posizione" --> che provoca una modifica del tempo medio di attesa. (Miglioria). Il job lungo avra' un peggioramento in termini di servizio di 3 (lunghezza job piccolo), ma il miglioramento dell'attesa del job piu' corto sara' nell'ordine di grandezza della lunghezza del job lungo.    
  
In ultima analisi ho il vantaggio che il numeratore del ratio diminuisce, minimizzando la media ottimale. Questo tipo di problema e' del tipo **Algoritmo Greedy**. Applica una scelta locale di quello che sembra meglio ad ogni passo. Converge alla soluzione ottimale.  
  
Pero' stiamo lavorando sulla ipotesi specifica che i processi arrivino tutti assieme al tempo 0, ma non e' realistico.  
  
Esistono strategie migliori che possono fare di meglio --> includendo il fatto che i jobs possano arrivare scaglionati.  
  
* Nota:  Il tempo medio di completamento ha la stessa struttura del tempo medio di attesa .

## Shortest Remaining Time Next 

* Sistema SJF ma iniziamo a mettere in conto la prelazione.  
Il metro di valutazione per fare lo switch --> Il job appena arrivato 
Il tempo residuo e' piu' lungo del tempo di quanto il nuovo arrivato ci mettera' a fare le proprie operazioni : **SWITCH in corso** che fa intendere l'utilizzo di prelazione.   

[ . . . ] Esercizi sul tempo di scheduling e confronto tra algoritmi al pari di processi in arrivo  
  
## Scheduling Round-Robin  

* Versione con prelazione del First Come First Served  
* Pre-emptive e **basato su un quanto di tempo**(Timeslice).   
Se il quanto di tempo non viene rispettato scatta la prelazione: il sistema operativo si riserva di, in base a una certa condizione, di riprendersi la CPU. Qui il concetto rimane lo stesso ma la condizione non e' piu' SJF ma --> 
* La condizione che fa scattare la prelazione non per forza a favore di un candidato migliore ma di sicuro in base a un altro candidato. Si usa una coda FIFO --> Si assegna la CPU a chi sta in testa alla coda. Puo' essere visto come un algoritmo FIFO a cui abbiamo collegato la prelazione. Se un processo viene prelazionato vuol dire comunque che il suo stato viene salvato ma viene rimesso alla fine.  
  
Il processo che stava usando il suo quanto di tempo interrompe il suo utilizzo --> Il fatto che ancora aveva bisogno del tempo non importa. L'utilizzo del suo quanto di tempo --> Nello stato di bloccato. Non viene in uqesl caso rimesso nella coda dei processi pronti. --> Che puo' essere vuota se tutti i processi si blocchino per diverse ragioni --> Poi si sbloccheranno e lo scheduler avra' qualcosa da fare.  

Quando assegno la CPU a uno dei processi:  
1. Esso puo' chiudersi da solo e commettere harakiri 
2. Si blocca, quanto di tempo usato solo parzialmente. Quando si sblocchera' verra' rimesso in coda dei processi pronti.  
3. Scatta la prelazione.  
  
Ogni quanto **q** vale circa 20-50 millisecondi. Con **n** processi e un quanto di **q** ms, ogni processo avra' diretto a circa **1/n** della CPU e attendera' al piu' **(n-1)q ms**.  
  
**Aumento della reattivita**'. Se ho n processi, metto un processo in coda alla fine. Questo processo rivedra' la CPU al massimo in (n-1)q ms, quando tutti avranno usato la CPU nella propria interezza (caso peggiore: tutti hanno utilizzato al massimo il proprio quanto di tempo)  
  
Se scelgo un quanto piccolo aumento il numero di context switch forzati (si alza l'overhead totale)  
  
Se scelgo un quanto troppo grande, il processo si interrompera' prima di prelazionare. A parita' di comportamento --> asintoticamente se ingrandisco il quanto, l'algoritmo coincidera' con un algoritmo FIFO.  Non piu' interattivo.  
  
Pero' comunque i tempi saranno parametrici e non hardcoded. Cambiero' la grandezza del quanto, possibilita' di variare variabile ed efficienza del kernel per adattarlo al mio sistema, pur mantenendo kernel e algoritmo uguale.  

### Sistemi interattivi e priorita' 

* Non e' detto che tutti i processi siano uguali tra loro e che debbano avere la stessa priorita'.  Ci saranno priorita' maggiori e minori. Ci sono range diversi rispetto ai quali posso assegnare priorita'. (Esempio: numeri maggiori per priorita' maggiori oppure numeri minori per priorita' maggiori. Implementazione cambia, concetto rimane uguale).  
  
* **Cerco di dare un servizio migliore ai processi con priorita' piu' e' alta**. Ma quanta gliene devo dare?  
  
* Chi assegna le priorita'? --> 

* Ad esempio: processi piu' piccoli piu' ad alta priorita'. 

* Discrimen della lunghezza della CPU Burst; differenze CPU-Bounded e IO-bounded. E' piu' probabile che un processo IO-Bounded tenda a usare solo parzialmente il proprio quanto di tempo, perche' spesso si blocca da se'. Invece, un processo che tende ad avere CPU-bursts piu' lunghi verra' tagliato in piu' quanti.  
  
* **Euristica** = buona idea che *sembra* funzionare. (????? non sembra questa la definizione)  
  
* Idea = valutare l'intervallo di tempo effettivamente usato. L'SO lo puo' fare (e valutare anche quanto ne usi rispetto a quanto ne ha (monitoraggio in percentuale)).  Non viene fatto sul singolo evento ma viene fatto in base agli ultimi quanti. Monitorando cosi' avrei metodi per assegnare le priorita' in maniera piu' oculata  
  
Se metto come priorita' alta i processi IO bounded favorisco una interattivita' migliore. I CPU bounded utilizzeranno la CPU nel tempo lasciato dagli IO bounded e funziona: garantisce un sistema interattivo e un uso bilanciato dei CPU bounded.  
  
* Meccanismo legato ai quanti. Etichetta di priorita' data su 1/quanto di tempo utilizzato. Se utilizzo al 50%, **la priorita' cresce mano a mano che l'utilizzo diminuisce, perche' il processo ci stara' meno.**  
  
* Oppure abbiamo delle priorita' statiche (Talvolta ereditate). Le priorita' hanno un impatto sul modo in cui utilizzo le risorse del calcolatore. Tutte le risorse sono preziose e nei sistemi devono essere usate con parsimonia. I meccanismi di priorita' vengono usati con questo in mente: si evita che la CPU venga monopolizzata da qualcuno.  
  
* Esempio: mining con la CPU lo piazziamo con priorita' bassa perche' altrimenti si mangerebbe tutta la CPU --> Utilizza il resto di quello che i processi IO lasciano.  
  
* Alcuni processi o collezioni di processi sono trattati di base con una priorita' molto alta (Es: grafica interattiva)  
  
* --> Assegna a quello con la priorita' piu' alta. Quando si blocca esce dai processi pronti. Se anche quelli con media priorita' escono dalla coda allora anche quelli a bassa priorita' arriveranno a usare la cpu.  Ma non e' detto: magari un gruppetto di alta priorirta' continano ad alternarsi; cosi' non da' garanzia sul momento in cui arrivero' a usare la CPU ma non per fortuna ma voglio averne la garanzia  

## Aging

Idea dell'invecchiamento. Meccanismo che fattorizza l'eta' di un processo nella coda. Alza la priorita' dei processi che stanno da tanto tempo in coda, finche' essa supera prima o poi quello di priorita' superiore. Solo che e' un innalzamento transitorio.  
  
Quando arriva a usarla poi la priorita' scendera' di nuovo di botto (aging azzerato). Anche una situazione che avrebbe potrtato alla starvation cosi' riesce a usare almeno un po' della CPU.  
  
## Scheduling a code multiple  
  
Molto vicino a come effettivamente funziona (su windows).  
Implemento una coda di code di priorita'. E' un vettore di code in cui vado a raggruppare processi di medesima priorita' nella stessa coda. In ogni coda minore i processi sono omogenei.  
  
1. Scegliere quale coda attenzionare (qui parliamo di scheduling verticale)  
    * Idea di scegliere la coda non vuota piu' alta. 
2. **Specializzare un altro algoritmo di scheduling SPECIFICO all'interno di ogni coda** !! 

Posso suddividere la scelta in una serie di passi e scegliere algoritmi diversi in base ad ogni coda.  

Potrei usare il round robin all'interno di ogni coda di priorita'. (Quanto di tempo per ognuno dei processi). Potrei fare cosi' e scegliere un quanto di tempo diverso per ogni coda di priorita'.  

* Posso mettere gli IO bounded nelle classi a piu' alta priorita' e quelli CPU bounded nelle priorita' piu' basse. Idealmente nel mezzo ci sono processi che sono misti tra CPU e IO bound.  
  
Posso usare la roundrobin per ogni coda delle priorita' con dei quanti di tempo diversi. **Metto quindi un quanto di tempo piu' breve per processi con priorita' piu' alta**. **Man mano che scndo di priorita' il q aumenta.**  
  
Ultima priorita' --> **q di tempo infinito =  First come first served. A patto che non ci siano altri processi che hanno priorita' maggiore.**  
  
Bisogna anche sistemare le priorita' in maniera ponderata. Questi sistemi possono **fare cambiare la priorita' ai processi in base al loro comportamento**. Ce n'e' una base (Per tutti uguali oppure arrivata per ereditarieta') e potrebbe cambiare. All'atto dell'inserimento nella coda di nuovo il RoundRobin potrebbe scegliere di inserirlo in un'altra coda.  

* Queste euristiche permettono di mutare lo scheduling in base al comportamento dei processi stessi.  

* Cambiando lo scheduling verticale posso risolvere il problema a cui avevamo messo una pezza con l'aging (?). Un modo piu' elegante e' il cambiare lo scheduler verticale e applico invece un round robin a cui assegno una certa percentuale di uso della CPU ad ogni "classe". 
* Torneo a turno 5sec: il 50% lo do' ai processi della prima coda. 
* Quando ho finito il 50%, uso poi il 30% della seconda coda in base al quanto di tempo tipico della seconda coda.  

Faccio un lavoro di questo tipo 

|   50%     | 4     |  
|   30%     | 3     |  
|   15%     | 2     |   
|   5%      | 1     |  

Questi processi avranno garantita un po' di CPU. E' una promessa e non "prendono la cpu per fortuna" 