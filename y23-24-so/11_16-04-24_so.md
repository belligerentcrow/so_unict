# 11 Lezione -- Sistemi operativi 

---

<!-- TOC -->
- [Shortest Process Next (SPN)](#shortest-process-next-spn)
- [Scheduling nei sistemi interattivi](#scheduling-nei-sistemi-interattivi)
    - [Scheduling Garantito](#scheduling-garantito)
    - [Scheduling a lotteria](#scheduling-a-lotteria)
    - [Scheduling Fair-Share](#scheduling-fair-share)
- [Scheduling dei thread](#scheduling-dei-thread)
- [Scheduling su Sistemi Multiprocessore](#scheduling-su-sistemi-multiprocessore)
    - [Multielaborazione asimmetrica](#multielaborazione-asimmetrica)
    - [Multielaborazione simmetrica](#multielaborazione-simmetrica)
    - [Migrazione spontanea](#migrazione-spontanea)
- [Cosa usano i sistemi operativi moderni?](#cosa-usano-i-sistemi-operativi-moderni)
    - [Windows](#windows)
    - [Linux](#linux)
        - [Coda dei processi pronti:](#coda-dei-processi-pronti)
        - [Incremento](#incremento)
        - [Overflow](#overflow)
        - [Priorita'](#priorita)
    - [MacOS](#macos)
<!-- /TOC -->

---

EGG IS THE GOALBalls

---

## Shortest Process Next (SPN)
  
Altro modo di applicare il concetto di scheduling per brevita'.  
Applicare tutto questo ai sistemi interattivi che puo' portare a durate non prevedibili. Non e' chiaro come poter schedulare. --> Maggiore reattivita'.  
Il criterio di scelta per brevita' --> Lo applichiamo per altro. Invece per l'intero processo, applichiamo il concetto al singolo CPU burst. Quando il processo usa nella sua interezza la CPU senza interrompersi da se'.   
Obbiettivo e' di scegliere quello migliore--> quale? Assegnare la CPU a quello che me la tornera' prima.  
Questo mi assicura un avvicendamento piu' repentino tra i processi e si da' la CPU tra i due al processo che sara' piu' IO bounded dell'altro.  
Diamo la CPU al processo che ha una maggiore priorita'.  
Non dissimile al concetto di prima in cui scegliamo sempre quando possibile un processo IO-bounded.   
  
Previsione nel futuro in base ai quanti di tempo passati dei CPU bursts.  
Scelta per brevita' ma basandosi sulla stima dei passati CPU bursts per una stima di quanto durera' il prossimo.  

```S(i) e' una stima sull'evento T(i)```.  
L'idea e' di effettuare una previsione per l'evento futuro andando a fare una previsione dell'evento futuro valutando cio' che ho misurato di prima persona e cio' che era la stima precedente (la vado a misurare perche' puo' dare possibilita' di coinvolgere anche eventi non immediatamente trascorsi). S(i) contiene anche S(i-1) e T(i-1), e a sua volta S(i-2) e T(i-2) etc.  
  
Si tratta di convolgere 2 eventi, S(i) e T(i) dove T(i) ripende da S(i-1). Il parametro a e' un numero tra 0 e 1 e va a pesare e mediare uno dei due fattori diversamente. Se scelgo a = 1/2 sto facendo solo la media tra quello di prima e quello dopo.  
Se azzecco il valore non cambio.  (?)  
Se utilizzo un parametro piu' vicino a 0, sto dando molto peso alla vecchia stima e sto tenendo conto di meno della stima "odierna". Succede il contrario scegliendo un valore piu' vicino a 1.  Ma scegliere un valore troppo vicino a 1 porta anche a prendere stime "nervose" ovvero stime che cambino molto velocemente.  
  
## Scheduling nei sistemi interattivi 

### Scheduling Garantito 

Idea di base: effettuiamo delle promesse e cerchiamo di rispettarle. Possiamo tener traccia per ognuno dei processi di quanto ognuno di questi processi abbia fatto uso della CPU. Se non rispetto le promesse effettuo delle scelte. Le promesse sono diverse fra di loro e dipendono anche dalla priorita'.  
Viene stabilita una percentuale di utilizzo e viene fatta rispettare.  

### Scheduling a lotteria

<img src="./Oliver_Swanick.jpg" width="300">

Biglietti con estrazioni randomiche --> Processo semplice e chiaro. Possibilita' di avere processi cooperanti.  
--> Un processo potrebbe cedere dei tickets al figlio. Potrebbe anche eccedere ovvero darne una buona parte per collaborare (anche troppi), boost di priorita' che gli permette di fare quello che deve fare velocemente per poi riottenere i ticket in eccesso.  


### Scheduling Fair-Share  
  
Tendo a dare 1/n a tutti -> Ma non e' detto che sia equa in un multiutente. Se ho uno sbilanciamento nel numero dei processi per utente 

---

Processi ad alta priorita' dovrebbero avere diverse priorita'.  
I processi hanno la possibilita' di influenzare la priorita', sono cambiamneti manuali della priorita' base e tipicamente si possono solo diminuiti. NOn posso aumentare di priorita' o lasciare che si possa aumentare la priorita' come si vuole.  

Ci devono essere limiti di come si possono abbassare. Fa eccezione l'amministratore; che puo' anche dare priorita' molto alte.  

---

## Scheduling dei thread  
  
* Utente 

Ripropone in scala minore la scelta (cosa succede ad un thread utente che cede alla libreria utente) --> problema di scelta. Abbiamo un piccolo scenario di algoritmo di scelta. E' una scelta limitata (senza prelazione) con la thread yield.  

* del Kernel 

Doppia scelta. Non scelgo il processo e poi il thread al suo interno ma i thread vengono raggruppati per risorse, e le risorse legate ai thread sono quelle che usano (file aperti, memoria usata etc). Il tipo di scelte valgono ancora. Al piu' posso ponderare il costo del context switch che e' minore nel caso in cui il costo del thread schedulato sia minore rispetto ad un altro.  
  
--- 
  
## Scheduling su Sistemi Multiprocessore
  
* possibili approcci e politiche di scheduling.  


### Multielaborazione asimmetrica

La prima scelta e' capire cosa deve fare la CPU. Buona parte delle scelte e gestione di strutture dati etc vengono gestite dalla CPU master. Ovvero grosse parte delle cose vengono fatte nella CPU master. La cpu slave si occupano dei processi utente.  Ma non si usa piu' perche' scala male se c'e' un solo master che coordina tutti gli altri processori. Diventa un collo di bottiglia.  

### Multielaborazione simmetrica

Non crea colli di bottiglia perche' ognuno fa il suo lavoro. Ma! Struttura di supporto alla scelta. Quando si libera uno dei processori ci sono diverse code dei processi pronti. Efficienza nell'uso delle strutture: efficienza legata alla concorrenza. Alcune delle strutture potrebbero essere usate da parte di piu' core  
Ma non scala bene neanche la coda dei processi pronti unificata, ne' le code separate per ogni processore perche' ci sarebbe overhead.  
  
N processori o N code private gestite 

[ . . . oops]

### Migrazione spontanea  
  
Viene applicata quando un core ha una coda vuota. Pull migration 

Il bilanciamento non e' l'unico degli obbiettivi ma c'e' anche l'uso che fanno i vari processi delle varie CPU. Se ho un processo che l'ultima volta che e' stato schedulato e' stato sulla CPU 1. 
  
Considerare il fatto che quando un processo e' in atto la cache inizia a riempirsi di records del processo in questione. La cache a volte viene azzerata, a volte non e' necessario che lo sia. E' una bella notizia perche' la cache si comportera' non benissimo (cache miss) che porteranno informazione utile al secondo processo --> Cosa succede quando si sono avvicendato il rpimo il secondo e poi di nuovo il primo --> Potenzialmente ci possono essere informazioni ancora utili al primo. Possibilmente e' piu' efficiente se schedulo X poi Y poi di nuovo X sulla stessa cpu. L'idea di cambiare ogni volta la cpu assegnata ad ogni quanto di tempo non e' una buona idea perche' utilizziamo male la cache. Questo ragionamento lascia intednere che 1. stiamo parlando di cache personale di ogni cpu. Ce ne possono essere condivise e private e noi stiamo ragionando sulle private.  
  
Le code sono separate ma l'idea di schedulare sempre lo stesso processo sullo stesso processore e' una buona idea.  
  
Questo fa nascere una affiliazione o predilezione di un processo per un processore e garantire questo vincolo e' Buono.  *"non e' attaccamento affettivo ma lo fa solo per il Cache" -cit*
  
Garantire predilezione perfetta in teoria dice che un processo non si puo' spostare ma questo cozza con l'idea del bilanciamento.  D'altro canto se utilizzo code separate ho una migliore scalabilita' e risolvo nel modo implicito la predilezione di un processo per un processore. Perche' se un processo sta in un acoda allora c'e' una predilezione per la predilezione. Un processo pero' puo' migrare da un processore a un altro. Predilezione che si distingue tra **predilezione debole** e **predilezione forte**. 
  
E' un meccanismo che non dovrebbe essere forzato ma sono i processi stessi o gli utenti che fanno male di implicare la predilezione; ma cosi' la predilezione non puo' avvenire, in caso di predilezione forte.  

## Cosa usano i sistemi operativi moderni?  
  
Elementi comuni: Thread, SMP, Gestione delle priorita', Predilezione per i processi IO-Bounded.  

### Windows

Scheduler basato molto su code di priorita'. 
Euristiche per migliorare il servizio dei processi interattivi e in particolare di foreground 
Euristiche per evitare il problema dell'inversione di priorita'
Altri boost di priorita' per processi predominantemente interattivi.  


### Linux 

Linux: scheduling a scelta basato su task (generalizzazione di processi e threads)
Completely Fair Scheduler (CFS): Moderno scheduler garantito 

Molto moderno. Garantito e va a misurare la CPU gestita da ogni Task e va a creare un bilanciamento dell'uso della CPU e il nome fair -->  
  
Scheduler garantito viene implementato tramite un processo di tracciamento dell'uso della CPU. Per ogni task si misura il tempo --> VIRTUAL CPU non per forza legata all'uso reale.  
  
Per ogni processo il sistema misura quanta CPU ha usato. Ha un numero. Questo numero inizia a crescere per quanto viene eseguito.  
  
Ragioniamo su una sola CPU.  Il virtual runtime inizia a crescere quando qualcosa ci gira sopra e allora per ogni task c'e' questo numero e ogni volta che voglio mettere qualcosa sulla CPU ci metto sopra quello che ha questo numero (virtual runtime) piu' piccolo. Legato al discorso delle promesse perche' cerco di equilibrarli tutti.  
  
Se quello era il piu' piccolo allora dopo un certo punto non sara' piu' il piu' piccolo e avverra' il context switch.  Solo 1 vede il VRT crescere --> un altro quindi gli subentrera' e questo e' l'evento che fa scattare la prelazione (non si usa il quanto di tempo ma un parametro legato a fin quando il controllo viene adeguato) (Granularita': posso modificare ogni quanto posso fare context switch e sistema interattivo piu' alto. Se ho una granularita' grossa allora il test viene fatto piu' staccato meno context switch etc. Scelta in base al VRT (Virtual Run Time).  
  
#### Coda dei processi pronti: 
Coda di priorita' basato sul Virtual Runtime che usa un Albero Rosso Nero per tenere organizzati i record dei suoi task. Albero binario di ricerca autobilanciato con la profondita' massima quasi bilanciata. Operazioni logaritmiche. Buono  
  
Il compito dello scheduler viene fatto prendendo quello con VRT piu' basso (basso a sx)  
  
#### Incremento 
il nodo si sposta verso destra (non sara' piu' l'ultimo ) e l'ultimo sara' il nuovo task schedulato.  
  
#### Overflow 
si normalizzano ogni tanto. Azzero il minimo e mantengo le posizioni. Se c'e' un nuovo arrivato allora non e' importante che numero sia ma che sia un numero diverso da tutti gli altri e che sia non troppo alto ne' troppo basso degli altri. 
  
#### Priorita'
Per fattori di decadimento se viene eseguito per 500k nanosecondi allora aumento di 500k? No, nel fare l'accounting e incrementare il VRT non e' detto che sia un conteggio 1:1 ma viene moltiplicato per un fattore di decadimento. Piccolo se la priorita' e' alta, grande per la priorita' minore.  
  
Viene garantito che ad un certo punto arriverano tutti a girare. SUl sistema linux --> Dell'albero la migrazione avviene da dx verso sx.  
  
A causa del fattore di rendimento pessimo il fattore di decadimento e' alto quindi arriva comunqeu ad usare la CPU.  

I processi che creo con la fork ognuno ha la propria working directory --> Forks vs Threads create  
  
La fork e la thread create --> come una clone?? Nesusno usa le clone --> Un algoritmo di scelta non va piu' con thread o processi ma come Tasks. 

Nessun programma 

### MacOS

Mach scheduler basato su code di priorita' con euristiche 