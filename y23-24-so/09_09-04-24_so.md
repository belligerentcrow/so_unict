# 9 Lezione -- Sistemi Operativi

---

<!-- TOC -->
- [Recap](#recap)
- [Problema dei Lettori-Scrittori](#problema-dei-lettori-scrittori)
    - [Soluzione 1: Semafori](#soluzione-1-semafori)
    - [Soluzione 2 : Monitor](#soluzione-2--monitor)
        - [Modifica per equita' tra scrittura e lettura](#modifica-per-equita-tra-scrittura-e-lettura)
        - [Modifica per favorire gli scrittori](#modifica-per-favorire-gli-scrittori)
- [Scheduling](#scheduling)
    - [Categorizzazione:  Processi CPU-bounded vs IO bounded](#categorizzazione--processi-cpu-bounded-vs-io-bounded)
        - [Cpu-bounded](#cpu-bounded)
        - [IO Bounded](#io-bounded)
    - [Context Switch](#context-switch)
- [Obbiettivi e metriche degli Algoritmi di Scheduling](#obbiettivi-e-metriche-degli-algoritmi-di-scheduling)
    - [Obbiettivi comuni](#obbiettivi-comuni)
        - [Equita' e Bilanciamento nell'uso delle risorse](#equita-e-bilanciamento-nelluso-delle-risorse)
    - [Sistemi batch](#sistemi-batch)
    - [Sistemi interattivi](#sistemi-interattivi)
    - [Sistemi real-time](#sistemi-real-time)
- [Scheduling nei sistemi batch](#scheduling-nei-sistemi-batch)
<!-- /TOC -->

---

* Forse bando di tutorato a maggio

## Recap 

* Problema dei 5 filosofi --> risorse limitate condivise  

## Problema dei Lettori-Scrittori

Vincoli piu' generali di prima -> Problema classico che modella l'accesso a un data-base  
Non tutti i processi fanno la stessa cosa -> Alcuni leggono altri modificano; distringuibili in:  
1. Lettori -> consultare database  
2. Scrittori -> modificarne il contenuto  
Problemi possono verificarsi anche tra lettura vs scrittura. Quindi una modifica non e' compatibili con altre operazioni. Ma le letture sono plausibili in contemporanea. Ci puo' essere al piu' un operatore all'interno della struttura (pero' rallenta la capacita' di consultare la struttura). I processi si bloccano quando non e' necessario e vanno piu' lenti. Regola che potrebbe essere troppo zelante. (Esempio: database di previsioni del tempo. Le letture sono piu' delle scritture.)  
  
* Strumenti di sincronizzazione tra lettori e scrittori.  

### Soluzione 1: Semafori  

```
function reader()
    while true do(){
        down (mutex);       // protezione accessi a variabile condivisa RC. per capire accesso 
        rc = rc+1;
        if (rc = 1) down(db);   // operazione bloccante dentro una sezione critica. ^[1]
        up (mutex);
        read_database();    //<---| 
        down (mutex);
        rc = rc-1;
        if (rc = 0) up(db);
        up (mutex);
        use_data_read();    //<--- |
    }
```

[1]^ puo' essere bloccante a cascata ma e' proprio quello che vogliamo. Se dopo si presentasse un lettore. Il primo si blocchera' a down(db), il secondo e terzo e quarto a down(mutex) e si accoderanno. Quando l'ultimo dei lettori avra' finito allora DB tornera' ad essere 1. Se nel frattempo si e' accodato qualche altro scrittore --> funziona.  Utilizza i semafori per proteggere da un lato il database dall'altro le variabili per segnalare i turni delle sezioni critiche. Quando ci sono lettori dentro il DB e arrivano altri lettori, i lettori scavalcano eventuali scrittori in fila. Gli scrittori entreranno solo quando tutti i lettori saranno usciti dal DB.

```[R1, R2] W1, W2... Wn   <-- R3```   
```[R1, R2, R3] W1, W2, ...Wn```
  


```c
semaphore mutex = 1;
semaphore db = 1;
int rc = 0;
```

```
function writer()
    while true do()
        think_up_data();
        down(db);           //<-- blocco eventuale scrittore ma blocco anche lettore se c'e' uno scrittore
        write_database();
        up(db);
```

* Qui il semaforo mutex va a proteggere la variabile RC. Vanno a conteggiare i vettori che leggono il database. 

Gli scrittori potrebbero aspettare tempi molto lunghi.  
  
Se c'e' uno scrittore e una coda di scrittori, i lettori si accoderanno agli scrittori. Se arriva uno scrittore, si accodera' a sua volta alle letture.  E' un metodo molto biased nei confronti delle letture.  

Un metodo per cambiare e' --> Fare in modo che un lettore in ritardo non scavalchi gli scrittori ma se c'e' almeno uno scrittore che aspetta, i lettori saranno accodati normalmente agli scrittori.  

Cosi' uno scrittore che si blocca non rischia di aspettare all'infinito ma ha un upper bound (operazioni dei W o dei R precedenti) che aspettera' prima di sbloccarsi.  
  
Conseguenze: peggioramento delle letture in parallelo. Blocco richieste perche' c'e' una sorta di inequita'. La situazione puo' essere anche ribaltata : magari potrebbe privilegiare le scritture in alcuni tipi di database implementati (es: DB previsioni meteo).

### Soluzione 2 : Monitor

```c
monitor rw_monitor
    int rc = 0; bool

    //VEDI SLIDE 


```
Dentro il monitor ci sono solo le start read/read e start write/write. Il DB viene consultato dalle ```write_database()``` e ```read_database()``` dentro ```reader()``` e ```writer()```.  Il database sta fuori dal monitor. Non aggiungo variabili condivise: il monitor garantisce il fatto che lo stiamo guardando in modo esclusivo.  
[ ... ]  
Lo scrittore si blocca sempre se c'e' qualcun altro presente nella struttura.  
* Uscita di uno scrittore: end_write  
Si va a controllare se qualcuno e' bloccato. Se c'e' lo risvegliamo (signal()). In questo caso decidiamo prima un lettore (o uno scrittore). Se vado a svegliare uno scrittore (se ci fossero piu' scrittori bloccati questo ne sveglia uno solo (garantisce la mutua esclusione nel DB.))  
Se c'e' almeno un lettore o un gruppo di lettori (che si e' accodato sulla condizione if busy on write wait read) allora lo scrittore che ha appena finito lancia una signal che ne sveglia uno.  
* Rispetto a quella di prima e' quasi uguale ma e' piu' esplicito rispetto alla coda di scrittori e lettori. Se ho una start read --> uno scrittore non potra' ufjhjgkhdgkjfkdkghkjfdgkf  
Anche qui c'e' una preferenza e lo scrittore puo' accodarsi all'infinito. Gli stessi effetti di prima con strumenti diversi.  
**importante** --> la signal ne sveglia solo uno ma diventa a cascata quando i read iniziano ad entrare.  

#### Modifica per equita' tra scrittura e lettura

```if (busy_on_write OR in_queue(write)) wait(read)```
  
Modifica del criterio di blocco per controllare se c'e' almeno uno scrittore in coda.  
Quando l'ultimo lettore termina manda la signal sulla write. Lo scrittore va a risvegliare, se c'e' un lettore, un lettore. Se nel frattempo sono arrivati altri lettori, si aggruppano al lettore!!  Ma quando finiscono i lettori si passano agli scrittori. In virtu' di fare in modo di evitare infinita attesa. Si crea un accodamento ma una volta che entra un lettore mentre sono dentro i lettori, il lettore non si accodera' su quelli che stanno gia' dentro il database ma si proseguira' con la coda di prima.  

#### Modifica per favorire gli scrittori

```c
function end_write()
    busy_on_write = falsel
    if(in_queue(write))
        signal(write)
    else
        signal(read)
```
  
Uno scrittore uscente dal DB favorisce un suo simile scrittore. Ma qui il gruppo di lettori potrebbero aspettare indefinitamente --> Starvation possibile  
  
* Throwback della implementazione **signal and return** dei monitor: quella piu' naturale con meno interlacciamento.  

---

## Scheduling 

Quale processo svegliare e dare alla CPU dalla coda dei processi pronti.  
Valutare quali siano le scelte migliori per i diversi tipi di sistemi.   
* **Algoritmo di Scheduling**
Compito semplice: da una serie di candidati presenti nella coda dei processi pronti scegliere il prossimo.  
* **Dispatcher**  
Stabilito chi e' il prossimo deve effettuare il **context switch**.  
  
In generale vale la regola --> quanto piu' e' efficiente e veloce l'algoritmo di scelta meglio e'. Bisogno di una scelta breve e a volte dipende dalla struttura dati che utilizzo/
Anche il Dispatching ha bisogno di fare un cambio di contesto veloce. Questo e' legato da quanti registri ho, dall'architettura, ma anche dalla scelta del processo.  Quando l'algoritmo di scelta sceglie uno che e' imparentato --> il dispatcher effettua azione piu' efficiente. Meno overhead. La scelta dell'algoritmo di scheduling va a influenzare la scelta dei passaggi successivi (in base a cosa effettivamente devo cambiare: se sono parenti devo cambiare meno cose --> esempio fork & exec).  
  
La scelta migliore non e' detto che sia chiaro. Dipende da quali processi ho di fronte. Quale e' la scelta migliore dipende da tanti fattori. Quale sistema ho, ma anche il tipo di clienti e processi che ho. Fanno tanto uso di IO? Tanta interattivita'? Computazione?  
  
### Categorizzazione:  Processi CPU-bounded vs IO bounded

#### Cpu-bounded  
preferisce usare la CPU rispetto a operazioni di IO. Long Bursts.  

Processo che utilizzera' di piu' la CPU. Ad esempio, algoritmo di ordinamento. (Prima carica i dati ma poi quello che fa' e' soprattutto computazione) Oppure un algoritmo di compressione.  
Di solito e' anche intervallato da azioni IO, ma e' maggiormente CPU-bounded.  
  
Evidenziamo fasi in cui utilizza la CPU rispetto a quando e' in attesa di eventi IO.  Long CPU burst vs short CPU burst. I motivi per cui un processo non usa la CPU possono essere diversi ma per adesso categorizziamo cosi'.  
I CPU bursts sono interrotti da chiamate di sistema o pause in cui non uso la CPU (bloccato per dati o chiamata di sistema etc).  

#### IO Bounded  
shorter bursts. Implica comunque uso della CPU ma l'uso della CPU e' funzionale a invocare prossime istruzioni di IO. Qualcosa che si occupi di aspettare socket di rete in cui non mi serve molto computare. Quello che e' omogeneo e' la lunghezza della pausa. --> cambia il fatto che il burst e' piu' corto e le pause piu' frequenti.  

* Qual e' quello migliore da pescare? Dipende. Non e' neanche detto che i processi siano di un solo tipo o anche che si comportino nello stesso modo in due momenti diversi.  (Computare, caricare caricare, computare).  
  
1. *Come identificare i comportamenti?*
2. Comprendere che non sono omogenei e netti.  
3. **Non sono le pause che si allargano ma i bursts che si accorciano.**    

Per questa ultima cosa: i processi tendono ad essere piu' veloci tanto piu' quanto sono IO bounded???  
  
Bisogna mischiarli in maniera che sembra inizialmente innaturale ma che in realta' e' quella buona (non fare domande).  
  
* Di solito si tende a preferire quelli IO bounded  
Perche' di base vuol dire che me la restituira' presto. La CPU si rendera' libera prima.  
Vedranno avvicendarsi molto gli IOb nella CPU ma la lasceranno presto e ad un certo punto i processi CPU bounded verranno presi e useranno la CPU. Fintanto che non arrivano nuovi IObounded.  
Assicurano quindi un buon utilizzo sia del comparto computazionale che quello dell'IO. Benefici su entrambi i campi.  
  
### Context Switch 

Avviene in situazioni chiave: processo smette di usare la CPU dopo averla usata o c'e' richiesta di creazione di un nuovo processo. Oppure e' legato a una operazione o richiesta bloccante che in quel momento ha il controllo della CPU. Allora l'unica CPU la sta usando questo processo che a questo punto fa una IOoperation, si blocca, entra nello stato di bloccato, la CPU si e' liberata, l'algoritmo di scheduling dice che ne prende un altro e lo mette nella CPU e avviene il Context Switch.  
* Nei sistemi con prelazione esistono altri modi in cui avviene il context switch (gli viene tolta) altrimenti un processo lascia la CPU solo se la lascia o qualcuno gliela toglie.(?)  
* Se un processo tiene la CPU e la monopolizza --> Non fara' piu' richiesta di chiamate di sistema. Nei sistemi interattivi NON ci piace perche' monopolizzerebbe la situazione.  
E' un problema ma non per i Dispatcher, che gli interessa portare delle tabelle che dicono che ho usato bene la CPU.  
  
[ ... ]  
  
Il concetto di prelazione vale per i processi ma vale anche per il kernel stesso  -- flussi legati a processi o interrupts. Le race conditions sono valutate in base di--> uno per gli interrupt, uno per altro, e nella loro concorrenza possono creare situazioni impreviste (race conditions per strutture dati interne al kernel. Bad!). Quindi in alcune situazioni voglio la prelazione in altre no.  

## Obbiettivi e metriche degli Algoritmi di Scheduling 
Gli obbiettivi possono cambiare in base al sistema.  
Potrebbero esserci obbiettivi comuni, o specifici in base allo scenario.  

### Obbiettivi comuni 

#### Equita' e Bilanciamento nell'uso delle risorse
Per **equita'** intendiamo che in assenza di altre indicazioni di altra natura, tutti i processi dovrebbero essere trattati nello stesso modo. Vorrei un sistema di scheduling che tratta tutti nello stesso modo ovvero che dovrei assegnare a tutti la possibilita' di usare la CPU nella stessa possibilita' e abilita' (1/n per n processi).  
Per **bilanciamento** intendiamo che se ho piu' CPU vorrei che siano utilizzate tutte in maniera bilanciata e lavorino la stessa quantita' di lavoro.  

* **Sistemi batch** datati ma la situazione si ripresenta --> transazioni provocati da sistemi che utilizziamo ogni giorno (bancarie, pagamenti).  

* **Sistemi interattivi** --> richieste che richiedono interazione. (Wow)  

### Sistemi batch  

Un job di questo tipo si ha un algoritmo con un codice prodotto dal programma e tramite un input ci vuole un output.  

**Obbiettivi**:   

* **Massimizzare la produttivita'** (**throughput**)  
massimizzare la quantita' rispetto al tempo. Piu' lavori = (piu') meglio (assai). (👍) Ma da sola non puo' essere l'unica metrica (altrimenti farei sempre jobs corti)  
* **Minimizzare tempo di completamento o di turnaround**   
Misura il tempo necessario per completare la gestione del singolo job. Dove si va a misurare dall'istante in cui e' messo in coda all'istante in cui e' completato. Non facciamo tanta prelazione perche' vogliamo che le cose siano effettivamente fatte. Misura che applico col singolo job: ma devo valutare tutto il batch. Devo misurare il tempo di turnaround di tutto e poi fare un ragionamento di gruppo tramite una media. Devo minimizzare il tempo. Meno tempo in media faccio aspettare un processo migliore e' il servizio che sto offrendo. Metrica che evita la situazione di prima.  (zzz)
* **Minimizzare tempo di attesa**  
Considerare che il tempo di completamento non e' qualcosa su cui l'algoritmo di scheduling puo' operare (e' una componente che c'e' sempre, come lo organizziamo organizziamo). A noi interessa il tempo di attesa, che e' quello che puo' essere effettivamente influenzato dal tempo di attesa. Questo puo' essere influenzato dalle scelte dell'algoritmo di scheduling.  

### Sistemi interattivi 
  
[ ... ] oops  
  
### Sistemi real-time

* **Rispetto delle scadenze**  
Utilizzano tecniche molto piu' semplici (no prelazione?) Sono time sensitive, semplici e prevedibili.  
Sono sistemi chiusi: logiche piu' semplici basandoci su sistemi basati su collaborazione semplicita' e prevedibilita'.  

## Scheduling nei sistemi batch 

Ci sono una lista di jobs nella coda ma c'e' un ordine per il quale i jobs sono stati inseriti nella coda.  

* **First Come First Served**
  
O per ordine di arrivo.   ![(Diagramma di Gant????????)](gant.jpg)    
Semplice coda FIFO

* **Shortest Job First**
(AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA)

* **Shortest Remaining Time Next** 