# 12 Lezione -- Sistemi Operativi 

---

<!-- TOC -->
- [Memoria](#memoria)
    - [Memoria centrale e processi](#memoria-centrale-e-processi)
    - [Modello 2](#modello-2)
    - [Modello 3](#modello-3)
- [Sistema Multiprogrammato -- Multiprogrammazione senza astrazione](#sistema-multiprogrammato----multiprogrammazione-senza-astrazione)
    - [Rilocazione](#rilocazione)
    - [Protezione della memoria](#protezione-della-memoria)
    - [Spazio degli indirizzi](#spazio-degli-indirizzi)
- [Swapping](#swapping)
    - [Frammentazione esterna e interna](#frammentazione-esterna-e-interna)
- [Gestione dell'allocazione](#gestione-dellallocazione)
    - [Bitmap](#bitmap)
    - [Lista dinamica dei blocchi liberi e occupati](#lista-dinamica-dei-blocchi-liberi-e-occupati)
    - [Ordinata per indirizzo](#ordinata-per-indirizzo)
        - [First fit](#first-fit)
        - [Next fit](#next-fit)
        - [Best fit](#best-fit)
        - [Worst fit](#worst-fit)
<!-- /TOC -->

---
>(ghy)
wawaluigi
---

## Memoria 

### Memoria centrale e processi 

* La CPU (a parte i registri che sono strettamente legati alla CPU stessa e la Cache) ha bisogno di tenere a portata di mano dei dati. La memoria centrale e' l'unica memoria a cui la CPU puo' accedere direttamente.  
  
* La CPU accede alla memoria centrale attraverso e a causa della normale esecuzione delle informazioni del codice che ci sta girando sopra (? okay)  

* Fetch = lettura dell'istruzione stessa. La decodifica in informazioni va in fase locale e la esecuzione puo' includere altri accessi. A volte anche multipli accessi a cascata. Possono essere accessi in scrittura. In generale l'esecuzione di una singola espressione puo' implicare diverse fetch/store in aree di memorie. Dal punto di vista della gestione della memoria possiamo analizzare l'uso della CPU come una sequenza di lettura e scrittura su alcune zone di memoria. Che tipo di gestione mi aspetto rispetto ai suoi diversi processi?  
  
* Gestire processi, esecuzione che ha bisogno di uno spazio di memoria per ognuno degli n processi. Con la memoria **RAM** (Random Access Memory), ampia area di memoria con indirizzi propri (Indirizzi Fisici) a cui la CPU puo' accedere specificando l'indirizzo con **fetch e store**. Possiamo fare delle richieste di fetch e store (in sequenza) sulla RAM. Tutto questo in genere passa da una componente specifica, la **MMU**. (memory management Unit)   
  
* In un sistema multiprogrammato, se ho n processi mi aspetto che ognuno abbia un proprio spazio di memoria. Mi aspetto che la RAM sia partizionata nei suoi utilizzatori. ci sara' una zona libera e anche il SO deve stare da qualche parte.  Una specie di multiplex nello spazio.  
  
* Ci sono molti limiti che grazie al cielo adesso non affrontiamo direttamente  
  
* Idea principale: risorsa RAM, e collocarvi sopra i processi. Inizialmente avevano un processo alla volta quindi semplice approccio di usare la memoria. Nella memoria fisica trovo spazio per il programma e stop. MSDos era monoutente e elementare e non c'era bisogno di avere soluzioni piu' sofisticate. Si caricavano le cose dal floppy.  
  
* Il sistema poteva risiedere nella RAM 

### Modello 2
  
Modello in cui il sistema operativo e' situato nella ROM (solo lettura) ma una procedura permetteva di cancellare e riscrivere e aggiornare.  

### Modello 3

Una via di mezzo : quella che effettivamente si usava nei MSDOS. sistema operativo in RAM, ma esiste anche la rom e programmi nella rom (dispositivi di input, cose per supportare i dispositivi, hard disk, gestione hardware ). Quello che stava nella BIOS.  

Problematiche elementari che doveva gestire un sistema monoprogrammato(?)  
  
## Sistema Multiprogrammato -- Multiprogrammazione senza astrazione  
  
Una serie di problematiche --> 
* Uno fra questi, fare funzionare gli indirizzi di memoria. La partizione dei programmi sulla RAM non e' fissa ?  
  
[...oops ]   

### Rilocazione
  
Bisogna prendere l'indirizzo e sommarlo a la grandezza del codice gia' utilizzato da un altro programma e fare un jump??  ??? profit  
  
Jumps relativi: jumps piccolini rispetto alla collocazione attuale. Il compilatore determina se sara' un jump assoluto o relativo. Il jump relativo e' una istruzione piu' piccola.  
Ma ha dei limiti perche' il delta e' piccolo e quindi limitato. Il compilatore lo usa per implementare loops.  
  
Invece una call a un indirizzo lontano (esempio funzioni), bisogna tradurre e aggiustare solo indirizzi assoluti perche' quelli relativi gia' funziona  
  
Oltre indirizzi relativi al codice ci sono anche quelli relativi ai dati. Se ho nel codice qualcosa che fa salti a indirizzi assoluti devo aggiustarli. Incarico al sistema operativo di fare tutto questo e vanno ad appesantire un po' il sistema di loading. Quindi piu' o meno alla fine funziona.  
  
Questo risolve il problema della **rilocazione**  
  
### Protezione della memoria  
  
Gli indirizzi generati dal codice, in caso di un salto o un errore o una corruzione non ho protezioni utilizzando la rilocazione.  
  
* Lock & Key:  nella PSW un registro con le chiavi. 256 porzioni con chiavi per i processi in esecuzione.  
Etichettava ogni porzione di memoria --> ogni processo sceglieva una chiave non usata e vengono segnata nella tabella di conseguenza. Locazioni assegnate a chiavi.  
  
La CPU ha una sua personale chiave caricata dentro alla CPU(?????) la quale in occasione di un fetch o store controlla che la chiave caricata al processo sia quella giusta per quella area di memoria. Se non e' giusto l'associazione viene negato l'accesso. Piu' grossa era la RAM piu' grossa era la tabella. 
  
Era gia' integrato nell'hardware, non nel software.  
  
### Spazio degli indirizzi  
  
* Idea: prendiamo per es. un processo p2. Nella MMU vengono messi due registri base e limite --> ch ee' informata della partizione su cui lavora P2 e si occupa di fare combaciare, quando faccio il context switch, di applicare i valori giusti per lavorare nello spazio del p2.  
  
La CPU genera un indirizzo logico che passa nelle mani dell'MMU, che prende l'indirizzo logico e lo confronta con l'indirizzo limite e controlla se sfora l'indirizzo limite, se lo sfora accade la tap addressing error che ha bisogno una specifica routine, una eccezione/errore. Errore fatale.   
  
Ha generato un indirizzo fuori dalla partizione. L'istruzione e' quella e il processo viene annullato e visto come un tentativo di fare qualcosa di strano.  
  
Non ci sono problemi di protezione. Quindi la rilocazione? Trasformo il 1000 in 50000?? EH? KO 
 
E' l'hardware che fa questo lavoro in piu'.  
  
Da indirizzo logico (pensato dal compilatore dove si parte sempre dall'indirizzo 0) a indirizzo fisico (nella RAM). Funziona l'indirizzo logico per il concetto di astrazione della CPU virtuale e il processo singolo per ogni CPU. Qui l'astrazione diventa lo spazio di indirizzamento logico che viene tradotto in indirizzamento fisico.  

Usata su CDC 6600 e Intel 8088.  
  
---

Non e' possibile riprogrammare la MMU in modalita' utente e provochera' una eccezione  

---

## Swapping  
  
L'occupazione di memoria puo' cambiare e non essere prevedibile. Allora quanto deve essere grande il partizionamento?  
Esigenza di accomodare le esigenze dinamiche dei processi.  
--> Nota: potrebbero esserci aree occupate e aree libere. Ad un certo punto a causa delle allocazioni e delocazioni possiamo averne molti e sulla carta ho 500kb liberi ma scollegati tra loro per esempio. Come si risolve?  
  
Sposto e ricompatto lo spazio libero in maniera di avere 500kb di memoria libera contigua. Sulla carta funziona ma e' molto poco invitante dal POV dell'overhead. Quindi non 'e una grande idea.   
  
Idea di buttare fuori un processo per accontentare l'ultimo arrivato.Wtf Non lo uccido ma lo parcheggio su disco. E' in uno stato di ibernazione e il contenuto del suo spazio di indirizzamento e' stato copiato paro paro su disco. Non c'entra niente con l'area di swap di windows.  
  
* Il livello di multiprogrammazione e' seriamente limitato dalla dimensione della memoria centrale.  

Swap in and swap out dalla memoria centrale al disco.  

---
  
### Frammentazione esterna e interna

* Frammentazione interna e' uno spreco: ho una entita' che mi ha chiesto un certo spazio e alloco piu' spazio di quello che mi e' stato chiesto. Spazio sprecato che non sara' usato.    

---

## Gestione dell'allocazione  

Ho la memoria ram che puo' essere vista come una serie di spazi allocati. Come fa il SO a tenere traccia di tutto? Ho una esigenza di tracciamento. Abbiamo una serie di strutture statiche e dinamiche.  


### Bitmap  
Dividere la RAM in blocchi di dimensioni fisse in cui la immagino suddivisa. In questo modo basta una bitmap che abbia tanti bit quanti sono i blocchi in cui la divido. Posso tenere traccia di tutto questo. Posso individuare con una richiesta. Bit conseguenziali che individuano dello spazio libero contiguo. Lo spostero' nella bitmap a 1 cosi' so' che adesso e' occupata. Ma ha dei limiti! Dove la memorizzo? In memoria. Ma lo spazio che uso / spreco per memorizzare la bitmap lo rubo ai processi. E ha una dimensione statica. La dimensione dipende da quanta RAM ho e da quanto e' grossa la dimensione del blocco. Chiaramente se ho blocchi grossi ci saranno meno blocchi. Sembra una buona idea gestire la locazione in blocchi. Perche' scegliere unita' di allocazione molto piccoli fanno crescere la bitmap. Se avessimo un blocco per word avremmo una bitmap con 1/32esimo della RAM!!   
Spreco: quando un processo si istanzia 

Ragionamento statistico. Posso prevedere lo spazio sprecato della richiesta? Se sono fortunato l'ultimo blocco sara' pieno dove la richiesta che ho fatto e' un multiplo della word. se ho per esempio 8k+1bit ho proprio sfiga perche' devo allocare tutta la word dopo. Statisticamente l'ultimo blocco e' allocato a meta'. Spreco di circa 4k. Se lo moltiplico ho una stima di circa . nProcessi x 4k di spreco per frammentazione interna del sistema.  

Sembra risolvere il problema ma ha anche delle dimensioni importanti. Non e' gratuita.  

### Lista dinamica dei blocchi liberi e occupati  

Tiene traccia dello stato di allocazione della memoria centrale. Si tratta di un nodo con una parte informativa.   
  
[P 05] --> [H 53] --> [P 86] etc  
  
Equivalente di quello che rappresenta la bitmap. Posso individuare buchi e dati.  
Ma e' una struttura dinamica e non banale / non binaria.  
Svantaggio: caso di una lista molto lunga con tanti buchi.  Potenzialmente la struttura diventa molto grande e pesante. Dinamicita' che puo' pagare o meno in base alle situazioni. Permette di rappresentare la struttura in maniera piu' fedele della bitmap e piu' granulare.  
  
### Ordinata per indirizzo  

hhhhhh
Ma mantenendola allocata per indirizzo ci sono anche dei vantaggi: quando il processo termina il suo nodo si trasforma in un buco. se lo rappresento organizzato per indirizzi posso fare una gestione e manutenzione di questa lista facendo scattare una situazione di coalescenza. Coalescenza dello spazio

Buci get big togheter.  
  
Un buco + un buco = un buco piu' grande. Fattuale.  

[... oops]

Problema: c'e' un modo migliore di accorpare i buci?  In che modo misuro come fare la scelta? Simulazioni? vari algoritmi? Per misurare il grado di frammentazione esterna.  
  
C'e' una strategia che rende possibile il fenomeno della frammentazione esterna? (Tanti piccoli buchi con delle richieste).  
  
Da questo pov e' stato Ponderato quale potrebbe esser euna soluzione migliore. 
  
* **first fit**, **next fit, best fit, worst fit**

Adesso non si usano ma in nicchie piu' piccole e sistemi embedded sono molto importanti.  
  

![this is my hole meme](./enigma.jpg)  


#### First fit  
  
Ho una richiesta di una certa taglia in una situazione con una certa serie di buchi e la tecnica 1 e' di analizzare la mia lista e trovare il primo buco libero utile. Scansiono dall'inizio della memoria alla fine fino a trovarne uno dove ci entra. Se sono fortunata allora ci metto il programma dentro  

#### Next fit

Applica la stessa strategia ma ricorda dove si era fermato l'ultima volta nella ricerca e continua da li'. In realta' non fa differenza   

#### Best fit  
  
Cerca di ottimizzare la scelta e cerco il blocco migliore che cerca di minimizzare quanto resta di spazio. Scansiona tutti i blocchi. E se ne trovo uno della taglia esatta si ferma li'. 
Questo potenzialmente e' piu' lento perche' deve scansionare l'intera lista a meno di trovare un buco perfetto. (that's what she said)  
  
#### Worst fit 

Va a scegliere nei blocchi idonei quello piu' grande.   

In realta' nessuno degli altri va tipo malissimo o meglio del first fit.  
  
Il worst fit per capire qual e' il blocco piu' grande devo scansionare tutto.  O(n)  
  
Potrei anche invece di ordinarli per indirizzi ordinarli per dimensioni.  
Questo permette di implementare in maniera ottimale gli ultimi due algoritmi 